{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bdbd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0,MobileNet  \n",
    "#from tensorflow.keras.applications import MobilNet\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from numpy.linalg import norm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bea449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D,Dense\n",
    "embedding_size = 1024\n",
    "\n",
    "# Load pre-trained SqueezeNet model without top (fully connected) layers\n",
    "base_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape = (224,224,3))\n",
    "\n",
    "#Remove the last layer of MobileNet\n",
    "base_model_output = base_model.layers[-1].output\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "# Step 3: Adjust the architecture for retrieval\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add the final Dense layer with embedding_size\n",
    "embeddings = Dense(embedding_size)(x)\n",
    "\n",
    "# Add L2 normalization layer\n",
    "\n",
    "\n",
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, axis=-1, epsilon=1e-12, **kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.math.l2_normalize(inputs, axis=self.axis, epsilon=self.epsilon)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(L2Normalization, self).get_config()\n",
    "        config.update({'axis': self.axis, 'epsilon': self.epsilon})\n",
    "        return config\n",
    "\n",
    "    # Apply L2 normalization\n",
    "    \n",
    "embeddings = tf.keras.layers.Dense(embedding_size)(x)\n",
    "embeddings = L2Normalization()(embeddings)\n",
    "\n",
    "\n",
    "feature_extraction_model1 = Model(inputs=base_model.input, outputs=embeddings)\n",
    "\n",
    "feature_extraction_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39092eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base model\n",
    "base_model2 = EfficientNetB0(weights='imagenet', include_top=False,input_shape = (224,224,3))\n",
    "base_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define the layers for the second parallel network\n",
    "# You can define them similar to the first one\n",
    "layer4 = base_model2.get_layer('block2a_expand_activation').output\n",
    "layer5 = base_model2.get_layer('block4a_expand_activation').output\n",
    "layer6 = base_model2.get_layer('block6a_expand_activation').output\n",
    "# Apply Global Average Pooling to each feature from the third layer\n",
    "layer4 = GlobalAveragePooling2D()(layer4)\n",
    "\n",
    "# Apply Global Average Pooling to each feature from the fourth layer\n",
    "layer5 = GlobalAveragePooling2D()(layer5)\n",
    "\n",
    "\n",
    "layer6 = GlobalAveragePooling2D()(layer6)\n",
    "\n",
    "# Concatenate the feature vectors from the second set of layers\n",
    "concatenated_features2 = Concatenate()([layer4, layer5, layer6])\n",
    "\n",
    "# Create a model for feature extraction\n",
    "feature_extraction_model2 = Model(inputs= base_model2.input, outputs= concatenated_features2)\n",
    "\n",
    "\n",
    "feature_extraction_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of files of dataset\n",
    "extensions = extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.bmp', '.BMP']\n",
    "\n",
    "def get_file_list(root_dir):\n",
    "    file_list = []\n",
    "    counter = 1\n",
    "    for root, directories, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(ext in filename for ext in extensions):\n",
    "                file_list.append(os.path.join(root, filename))\n",
    "                counter += 1\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain file names \n",
    "import os\n",
    "# path to the datasets\n",
    "root_dir = 'C:\\\\Data Drive\\\\Datasets\\\\101_ObjectCategories-20230908T025813Z-001\\\\101_ObjectCategories'\n",
    "filenames = sorted(get_file_list(root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81edc66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning labels to dataset\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(root_dir)\n",
    "data_dir\n",
    "dataset_labels=[]\n",
    "\n",
    "object_categories_dict = {\n",
    "     #'BACKGROUND_Google': list(data_dir.glob('BACKGROUND_Google/*')),\n",
    "     'Faces': list(data_dir.glob('Faces/*')),\n",
    "     'Faces_easy': list(data_dir.glob('Faces_easy/*')),\n",
    "     'Leopards': list(data_dir.glob('Leopards/*')),\n",
    "     'Motorbikes': list(data_dir.glob('Motorbikes/*')),\n",
    "     'accordion': list(data_dir.glob('accordion/*')),\n",
    "     'airplanes': list(data_dir.glob('airplanes/*')),\n",
    "     'anchor': list(data_dir.glob('anchor/*')),\n",
    "     'ant': list(data_dir.glob('ant/*')),\n",
    "     'barrel': list(data_dir.glob('barrel/*')),\n",
    "     'bass': list(data_dir.glob('bass/*')),\n",
    "     'beaver': list(data_dir.glob('beaver/*')),\n",
    "     'binocular': list(data_dir.glob('binocular/*')),\n",
    "     'bonsai': list(data_dir.glob('bonsai/*')),\n",
    "     'brain': list(data_dir.glob('brain/*')),\n",
    "     'brontosaurus': list(data_dir.glob('brontosaurus/*')),\n",
    "     'buddha': list(data_dir.glob('buddha/*')),\n",
    "     'butterfly': list(data_dir.glob('butterfly/*')),\n",
    "     'camera': list(data_dir.glob('camera/*')),\n",
    "     'cannon': list(data_dir.glob('cannon/*')),\n",
    "     'car_side': list(data_dir.glob('car_side/*')),\n",
    "     'ceiling_fan': list(data_dir.glob('ceiling_fan/*')),\n",
    "     'cellphone': list(data_dir.glob('cellphone/*')),\n",
    "     'chair': list(data_dir.glob('chair/*')),\n",
    "     'chandelier': list(data_dir.glob('chandelier/*')),\n",
    "     'cougar_body': list(data_dir.glob('cougar_body/*')),\n",
    "     'cougar_face': list(data_dir.glob('cougar_face/*')),\n",
    "     'crab': list(data_dir.glob('crab/*')),\n",
    "     'crayfish': list(data_dir.glob('crayfish/*')),\n",
    "     'crocodile_head': list(data_dir.glob('crocodile_head/*')),\n",
    "     'cup': list(data_dir.glob('cup/*')),\n",
    "     'dalmatian': list(data_dir.glob('dalmatian/*')),\n",
    "     'dollar_bill': list(data_dir.glob('dollar_bill/*')),\n",
    "     'dolphin': list(data_dir.glob('dolphin/*')),\n",
    "     'dragonfly': list(data_dir.glob('dragonfly/*')),\n",
    "     'electric_guitar': list(data_dir.glob('electric_guitar/*')),\n",
    "     'elephant': list(data_dir.glob('elephant/*')),\n",
    "     'emu': list(data_dir.glob('emu/*')),\n",
    "     'euphonium': list(data_dir.glob('euphonium/*')),\n",
    "     'ewer': list(data_dir.glob('ewer/*')),\n",
    "     'ferry': list(data_dir.glob('ferry/*')),\n",
    "     'flamingo': list(data_dir.glob('flamingo/*')),\n",
    "     'flamingo_head': list(data_dir.glob('flamingo_head/*')),\n",
    "     'garfield': list(data_dir.glob('garfield/*')),\n",
    "     'gerenuk': list(data_dir.glob('gerenuk/*')),\n",
    "     'gramophone': list(data_dir.glob('gramophone/*')),\n",
    "     'grand_piano': list(data_dir.glob('grand_piano/*')),\n",
    "     'hawksbill': list(data_dir.glob('hawksbill/*')),\n",
    "     'headphone': list(data_dir.glob('headphone/*')),\n",
    "     'hedgehog': list(data_dir.glob('hedgehog/*')),\n",
    "     'helicopter': list(data_dir.glob('helicopter/*')),\n",
    "     'ibis': list(data_dir.glob('ibis/*')),\n",
    "     'inline_skate': list(data_dir.glob('inline_skate/*')),\n",
    "     'joshua_tree': list(data_dir.glob('joshua_tree/*')),\n",
    "     'kangaroo': list(data_dir.glob('kangaroo/*')),\n",
    "     'ketch': list(data_dir.glob('ketch/*')),\n",
    "     'lamp': list(data_dir.glob('lamp/*')),\n",
    "     'laptop': list(data_dir.glob('laptop/*')),\n",
    "     'llama': list(data_dir.glob('llama/*')),\n",
    "     'lobster': list(data_dir.glob('lobster/*')),\n",
    "     'lotus': list(data_dir.glob('lotus/*')),\n",
    "     'mandolin': list(data_dir.glob('mandolin/*')),\n",
    "     'mayfly': list(data_dir.glob('mayfly/*')),\n",
    "     'menorah': list(data_dir.glob('menorah/*')),\n",
    "     'metronome': list(data_dir.glob('metronome/*')),\n",
    "     'minaret': list(data_dir.glob('minaret/*')),\n",
    "     'nautilus': list(data_dir.glob('nautilus/*')),\n",
    "     'octopus': list(data_dir.glob('octopus/*')),\n",
    "     'okapi': list(data_dir.glob('okapi/*')),\n",
    "     'pagoda': list(data_dir.glob('pagoda/*')),\n",
    "     'panda': list(data_dir.glob('panda/*')),\n",
    "     'pigeon': list(data_dir.glob('pigeon/*')),\n",
    "     'pizza': list(data_dir.glob('pizza/*')),\n",
    "     'platypus': list(data_dir.glob('platypus/*')),\n",
    "     'pyramid': list(data_dir.glob('pyramid/*')),\n",
    "     'revolver': list(data_dir.glob('revolver/*')),\n",
    "     'rhino': list(data_dir.glob('rhino/*')),\n",
    "     'rooster': list(data_dir.glob('rooster/*')),\n",
    "     'saxophone': list(data_dir.glob('saxophone/*')),\n",
    "     'schooner': list(data_dir.glob('schooner/*')),\n",
    "     'scissors': list(data_dir.glob('scissors/*')),\n",
    "     'scorpion': list(data_dir.glob('scorpion/*')),\n",
    "     'sea_horse': list(data_dir.glob('sea_horse/*')),\n",
    "     'snoopy': list(data_dir.glob('snoopy/*')),\n",
    "     'soccer_ball': list(data_dir.glob('soccer_ball/*')),\n",
    "     'stapler': list(data_dir.glob('stapler/*')),\n",
    "     'starfish': list(data_dir.glob('starfish/*')),\n",
    "     'stegosaurus': list(data_dir.glob('stegosaurus/*')),\n",
    "     'stop_sign': list(data_dir.glob('stop_sign/*')),\n",
    "     'strawberry': list(data_dir.glob('strawberry/*')),\n",
    "     'sunflower': list(data_dir.glob('sunflower/*')),\n",
    "     'tick': list(data_dir.glob('tick/*')),\n",
    "     'umbrella': list(data_dir.glob('umbrella/*')),\n",
    "     'watch': list(data_dir.glob('watch/*')),\n",
    "     'water_lilly': list(data_dir.glob('water_lilly/*')),\n",
    "     'wheelchair': list(data_dir.glob('wheelchair/*')),\n",
    "     'wild_cat': list(data_dir.glob('wild_cat/*')),\n",
    "     'windsor_chair': list(data_dir.glob('windsor_chair/*')),\n",
    "     'wrench': list(data_dir.glob('wrench/*')),\n",
    "     'yin_yang': list(data_dir.glob('yin_yang/*')),\n",
    "     'crocodile': list(data_dir.glob('crocodile/*')),\n",
    "     'trilobite': list(data_dir.glob('trilobite/*'))\n",
    "}\n",
    "object_labels_dict = {\n",
    "    #'BACKGROUND_Google': 0,\n",
    "     'Faces': 1,\n",
    "     'Faces_easy': 2,\n",
    "     'Leopards': 3,\n",
    "     'Motorbikes': 4,\n",
    "     'accordion': 5,\n",
    "     'airplanes': 6,\n",
    "     'anchor': 7,\n",
    "     'ant': 8,\n",
    "     'barrel': 9,\n",
    "     'bass': 10,\n",
    "     'beaver': 11,\n",
    "     'binocular': 12,\n",
    "     'bonsai': 13,\n",
    "     'brain': 14,\n",
    "     'brontosaurus': 15,\n",
    "     'buddha': 16,\n",
    "     'butterfly': 17,\n",
    "     'camera': 18,\n",
    "     'cannon': 19,\n",
    "     'car_side': 20,\n",
    "     'ceiling_fan': 21,\n",
    "     'cellphone': 22,\n",
    "     'chair': 23,\n",
    "     'chandelier': 24,\n",
    "     'cougar_body': 25,\n",
    "     'cougar_face': 26,\n",
    "     'crab': 27,\n",
    "     'crayfish': 28,\n",
    "     'crocodile_head': 29,\n",
    "     'cup': 30,\n",
    "     'dalmatian': 31,\n",
    "     'dollar_bill': 32,\n",
    "     'dolphin': 33,\n",
    "     'dragonfly': 34,\n",
    "     'electric_guitar': 35,\n",
    "     'elephant': 36,\n",
    "     'emu': 37,\n",
    "     'euphonium': 38,\n",
    "     'ewer': 39,\n",
    "     'ferry': 40,\n",
    "     'flamingo': 41,\n",
    "     'flamingo_head': 42,\n",
    "     'garfield': 43,\n",
    "     'gerenuk': 44,\n",
    "     'gramophone': 45,\n",
    "     'grand_piano': 46,\n",
    "     'hawksbill': 47,\n",
    "     'headphone': 48,\n",
    "     'hedgehog': 49,\n",
    "     'helicopter': 50,\n",
    "     'ibis': 51,\n",
    "     'inline_skate': 52,\n",
    "     'joshua_tree': 53,\n",
    "     'kangaroo': 54,\n",
    "     'ketch': 55,\n",
    "     'lamp': 56,\n",
    "     'laptop': 57,\n",
    "     'llama': 58,\n",
    "     'lobster': 59,\n",
    "     'lotus': 60,\n",
    "     'mandolin': 61,\n",
    "     'mayfly': 62,\n",
    "     'menorah': 63,\n",
    "     'metronome': 64,\n",
    "     'minaret': 65,\n",
    "     'nautilus': 66,\n",
    "     'octopus': 67,\n",
    "     'okapi': 68,\n",
    "     'pagoda': 69,\n",
    "     'panda': 70,\n",
    "     'pigeon': 71,\n",
    "     'pizza':72,\n",
    "     'platypus': 73,\n",
    "     'pyramid': 74,\n",
    "     'revolver': 75,\n",
    "     'rhino': 76,\n",
    "     'rooster': 77,\n",
    "     'saxophone': 78,\n",
    "     'schooner': 79,\n",
    "     'scissors': 80,\n",
    "     'scorpion': 81,\n",
    "     'sea_horse': 82,\n",
    "     'snoopy': 83,\n",
    "     'soccer_ball': 84,\n",
    "     'stapler': 85,\n",
    "     'starfish': 86,\n",
    "     'stegosaurus': 87,\n",
    "     'stop_sign': 88,\n",
    "     'strawberry': 89,\n",
    "     'sunflower': 90,\n",
    "     'tick': 91,\n",
    "     'umbrella': 92,\n",
    "     'watch': 93,\n",
    "     'water_lilly': 94,\n",
    "     'wheelchair': 95,\n",
    "     'wild_cat': 96,\n",
    "     'windsor_chair': 97,\n",
    "     'wrench': 98,\n",
    "     'yin_yang': 99,\n",
    "     'crocodile':100,\n",
    "     'trilobite':101,   \n",
    "}\n",
    "#class_to_numeric = {class_label: i for i, class_label in enumerate(set(class_labels))}\n",
    "for object_category,images in object_categories_dict.items():\n",
    "    for image in images:\n",
    "        dataset_labels.append(object_labels_dict[object_category])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "X, y = [], []\n",
    "for object_category,filenames in object_categories_dict.items():\n",
    "    for filename in filenames:\n",
    "        img = cv2.imread(str(filename))  # Convert Path object to string\n",
    "        resized_img = cv2.resize(img, (224, 224))\n",
    "        X.append(resized_img)\n",
    "        y.append(object_labels_dict[object_category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b574cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ca28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = X / 255.0  # Normalize pixel values to the range [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x dimensions:\", x.shape)\n",
    "print(\"y dimensions:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6263b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "features_model1 = feature_extraction_model1.predict(x)\n",
    "end_time = timeit.default_timer()\n",
    "elapsed_time = end_time - start_time  # Calculate the elapsed time\n",
    "print(f\"Elaapsed Time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "features_model2 = feature_extraction_model2.predict(x)\n",
    "end_time = timeit.default_timer()\n",
    "elapsed_time = end_time - start_time  # Calculate the elapsed time\n",
    "print(f\"Elaapsed Time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both concatenated feature vectors\n",
    "extracted_features = Concatenate()([features_model1,features_model2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels to the extracted features\n",
    "features_with_labels = list(zip(extracted_features, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage: Iterating over features with their labels\n",
    "for feature, label in features_with_labels:\n",
    "    # Access the feature vector and its corresponding label\n",
    "    print(\"Feature shape:\", feature.shape)\n",
    "    print(\"Label:\", label)\n",
    "    # Perform any operations using the feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88106999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the extracted features array\n",
    "features = tf.reshape(extracted_features, (len(extracted_features), -1))\n",
    "print(\"Reshaped features shape:\", features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d85c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming features is your tensor\n",
    "num_images, num_features_per_image = features.shape\n",
    "\n",
    "# Printing the values\n",
    "print(\"Number of images =\", num_images)\n",
    "print(\"Number of features per image =\", num_features_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae200089",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Assuming 'features' is a NumPy array containing your extracted features\n",
    "np.save('extracted_features_using_fusion_caltech101_effmobilnet.npy', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfb84e",
   "metadata": {},
   "source": [
    "# Reading and extracting features of query images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab6cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain file names \n",
    "import os\n",
    "# path to the datasets\n",
    "root_dir_query_images= 'C:\\\\Data Drive\\\\Datasets\\\\101_ObjectCategories-20230908T025813Z-001\\\\test'\n",
    "filenames_query_images = sorted(get_file_list(root_dir_query_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_query_images[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01998575",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_query_images = len(filenames_query_images)\n",
    "\n",
    "num_query_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c674e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning labels to dataset\n",
    "import pathlib\n",
    "data_dir_query = pathlib.Path(root_dir_query_images)\n",
    "#data_dir_query\n",
    "dataset_labels_query=[]\n",
    "\n",
    "object_categories_dict_q = {\n",
    "    #'BACKGROUND_Google': list(data_dir.glob('BACKGROUND_Google/*')),\n",
    "     'Faces': list(data_dir_query.glob('Faces/*')),\n",
    "    'Faces_easy': list(data_dir_query.glob('Faces_easy/*')),\n",
    "    'Leopards': list(data_dir_query.glob('Leopards/*')),\n",
    "    'Motorbikes': list(data_dir_query.glob('Motorbikes/*')),\n",
    "    'accordion': list(data_dir_query.glob('accordion/*')),\n",
    "    'airplanes': list(data_dir_query.glob('airplanes/*')),\n",
    "    'anchor': list(data_dir_query.glob('anchor/*')),\n",
    "    'ant': list(data_dir_query.glob('ant/*')),\n",
    "    'barrel': list(data_dir_query.glob('barrel/*')),\n",
    "    'bass': list(data_dir_query.glob('bass/*')),\n",
    "    'beaver': list(data_dir_query.glob('beaver/*')),\n",
    "    'binocular': list(data_dir_query.glob('binocular/*')),\n",
    "    'bonsai': list(data_dir_query.glob('bonsai/*')),\n",
    "    'brain': list(data_dir_query.glob('brain/*')),\n",
    "    'brontosaurus': list(data_dir_query.glob('brontosaurus/*')),\n",
    "    'buddha': list(data_dir_query.glob('buddha/*')),\n",
    "    'butterfly': list(data_dir_query.glob('butterfly/*')),\n",
    "    'camera': list(data_dir_query.glob('camera/*')),\n",
    "    'cannon': list(data_dir_query.glob('cannon/*')),\n",
    "    'car_side': list(data_dir_query.glob('car_side/*')),\n",
    "    'ceiling_fan': list(data_dir_query.glob('ceiling_fan/*')),\n",
    "    'cellphone': list(data_dir_query.glob('cellphone/*')),\n",
    "    'chair': list(data_dir_query.glob('chair/*')),\n",
    "    'chandelier': list(data_dir_query.glob('chandelier/*')),\n",
    "    'cougar_body': list(data_dir_query.glob('cougar_body/*')),\n",
    "    'cougar_face': list(data_dir_query.glob('cougar_face/*')),\n",
    "    'crab': list(data_dir_query.glob('crab/*')),\n",
    "    'crayfish': list(data_dir_query.glob('crayfish/*')),\n",
    "    'crocodile_head': list(data_dir_query.glob('crocodile_head/*')),\n",
    "    'cup': list(data_dir_query.glob('cup/*')),\n",
    "    'dalmatian': list(data_dir_query.glob('dalmatian/*')),\n",
    "    'dollar_bill': list(data_dir_query.glob('dollar_bill/*')),\n",
    "    'dolphin': list(data_dir_query.glob('dolphin/*')),\n",
    "    'dragonfly': list(data_dir_query.glob('dragonfly/*')),\n",
    "    'electric_guitar': list(data_dir_query.glob('electric_guitar/*')),\n",
    "    'elephant': list(data_dir_query.glob('elephant/*')),\n",
    "    'emu': list(data_dir_query.glob('emu/*')),\n",
    "    'euphonium': list(data_dir_query.glob('euphonium/*')),\n",
    "    'ewer': list(data_dir_query.glob('ewer/*')),\n",
    "    'ferry': list(data_dir_query.glob('ferry/*')),\n",
    "    'flamingo': list(data_dir_query.glob('flamingo/*')),\n",
    "    'flamingo_head': list(data_dir_query.glob('flamingo_head/*')),\n",
    "    'garfield': list(data_dir_query.glob('garfield/*')),\n",
    "    'gerenuk': list(data_dir_query.glob('gerenuk/*')),\n",
    "    'gramophone': list(data_dir_query.glob('gramophone/*')),\n",
    "    'grand_piano': list(data_dir_query.glob('grand_piano/*')),\n",
    "    'hawksbill': list(data_dir_query.glob('hawksbill/*')),\n",
    "    'headphone': list(data_dir_query.glob('headphone/*')),\n",
    "    'hedgehog': list(data_dir_query.glob('hedgehog/*')),\n",
    "    'helicopter': list(data_dir_query.glob('helicopter/*')),\n",
    "    'ibis': list(data_dir_query.glob('ibis/*')),\n",
    "    'inline_skate': list(data_dir_query.glob('inline_skate/*')),\n",
    "    'joshua_tree': list(data_dir_query.glob('joshua_tree/*')),\n",
    "    'kangaroo': list(data_dir_query.glob('kangaroo/*')),\n",
    "    'ketch': list(data_dir_query.glob('ketch/*')),\n",
    "    'lamp': list(data_dir_query.glob('lamp/*')),\n",
    "    'laptop': list(data_dir_query.glob('laptop/*')),\n",
    "    'llama': list(data_dir_query.glob('llama/*')),\n",
    "    'lobster': list(data_dir_query.glob('lobster/*')),\n",
    "    'lotus': list(data_dir_query.glob('lotus/*')),\n",
    "    'mandolin': list(data_dir_query.glob('mandolin/*')),\n",
    "    'mayfly': list(data_dir_query.glob('mayfly/*')),\n",
    "    'menorah': list(data_dir_query.glob('menorah/*')),\n",
    "    'metronome': list(data_dir_query.glob('metronome/*')),\n",
    "    'minaret': list(data_dir_query.glob('minaret/*')),\n",
    "    'nautilus': list(data_dir_query.glob('nautilus/*')),\n",
    "    'octopus': list(data_dir_query.glob('octopus/*')),\n",
    "    'okapi': list(data_dir_query.glob('okapi/*')),\n",
    "    'pagoda': list(data_dir_query.glob('pagoda/*')),\n",
    "    'panda': list(data_dir_query.glob('panda/*')),\n",
    "    'pigeon': list(data_dir_query.glob('pigeon/*')),\n",
    "    'pizza': list(data_dir_query.glob('pizza/*')),\n",
    "    'platypus': list(data_dir_query.glob('platypus/*')),\n",
    "    'pyramid': list(data_dir_query.glob('pyramid/*')),\n",
    "    'revolver': list(data_dir_query.glob('revolver/*')),\n",
    "    'rhino': list(data_dir_query.glob('rhino/*')),\n",
    "    'rooster': list(data_dir_query.glob('rooster/*')),\n",
    "    'saxophone': list(data_dir_query.glob('saxophone/*')),\n",
    "    'schooner': list(data_dir_query.glob('schooner/*')),\n",
    "    'scissors': list(data_dir_query.glob('scissors/*')),\n",
    "    'scorpion': list(data_dir_query.glob('scorpion/*')),\n",
    "    'sea_horse': list(data_dir_query.glob('sea_horse/*')),\n",
    "    'snoopy': list(data_dir_query.glob('snoopy/*')),\n",
    "    'soccer_ball': list(data_dir_query.glob('soccer_ball/*')),\n",
    "    'stapler': list(data_dir_query.glob('stapler/*')),\n",
    "    'starfish': list(data_dir_query.glob('starfish/*')),\n",
    "    'stegosaurus': list(data_dir_query.glob('stegosaurus/*')),\n",
    "    'stop_sign': list(data_dir_query.glob('stop_sign/*')),\n",
    "    'strawberry': list(data_dir_query.glob('strawberry/*')),\n",
    "    'sunflower': list(data_dir_query.glob('sunflower/*')),\n",
    "    'tick': list(data_dir_query.glob('tick/*')),\n",
    "    'umbrella': list(data_dir_query.glob('umbrella/*')),\n",
    "    'watch': list(data_dir_query.glob('watch/*')),\n",
    "    'water_lilly': list(data_dir_query.glob('water_lilly/*')),\n",
    "    'wheelchair': list(data_dir_query.glob('wheelchair/*')),\n",
    "    'wild_cat': list(data_dir_query.glob('wild_cat/*')),\n",
    "    'windsor_chair': list(data_dir_query.glob('windsor_chair/*')),\n",
    "    'wrench': list(data_dir_query.glob('wrench/*')),\n",
    "    'yin_yang': list(data_dir_query.glob('yin_yang/*')),\n",
    "    'crocodile': list(data_dir_query.glob('crocodile/*')),\n",
    "    'trilobite': list(data_dir_query.glob('trilobite/*'))\n",
    "}\n",
    "object_labels_dict_q = {\n",
    "    #'BACKGROUND_Google': 0,\n",
    "     'Faces': 1,\n",
    "     'Faces_easy': 2,\n",
    "     'Leopards': 3,\n",
    "     'Motorbikes': 4,\n",
    "     'accordion': 5,\n",
    "     'airplanes': 6,\n",
    "     'anchor': 7,\n",
    "     'ant': 8,\n",
    "     'barrel': 9,\n",
    "     'bass': 10,\n",
    "     'beaver': 11,\n",
    "     'binocular': 12,\n",
    "     'bonsai': 13,\n",
    "     'brain': 14,\n",
    "     'brontosaurus': 15,\n",
    "     'buddha': 16,\n",
    "     'butterfly': 17,\n",
    "     'camera': 18,\n",
    "     'cannon': 19,\n",
    "     'car_side': 20,\n",
    "     'ceiling_fan': 21,\n",
    "     'cellphone': 22,\n",
    "     'chair': 23,\n",
    "     'chandelier': 24,\n",
    "     'cougar_body': 25,\n",
    "     'cougar_face': 26,\n",
    "     'crab': 27,\n",
    "     'crayfish': 28,\n",
    "     'crocodile_head': 29,\n",
    "     'cup': 30,\n",
    "     'dalmatian': 31,\n",
    "     'dollar_bill': 32,\n",
    "     'dolphin': 33,\n",
    "     'dragonfly': 34,\n",
    "     'electric_guitar': 35,\n",
    "     'elephant': 36,\n",
    "     'emu': 37,\n",
    "     'euphonium': 38,\n",
    "     'ewer': 39,\n",
    "     'ferry': 40,\n",
    "     'flamingo': 41,\n",
    "     'flamingo_head': 42,\n",
    "     'garfield': 43,\n",
    "     'gerenuk': 44,\n",
    "     'gramophone': 45,\n",
    "     'grand_piano': 46,\n",
    "     'hawksbill': 47,\n",
    "     'headphone': 48,\n",
    "     'hedgehog': 49,\n",
    "     'helicopter': 50,\n",
    "     'ibis': 51,\n",
    "     'inline_skate': 52,\n",
    "     'joshua_tree': 53,\n",
    "     'kangaroo': 54,\n",
    "     'ketch': 55,\n",
    "     'lamp': 56,\n",
    "     'laptop': 57,\n",
    "     'llama': 58,\n",
    "     'lobster': 59,\n",
    "     'lotus': 60,\n",
    "     'mandolin': 61,\n",
    "     'mayfly': 62,\n",
    "     'menorah': 63,\n",
    "     'metronome': 64,\n",
    "     'minaret': 65,\n",
    "     'nautilus': 66,\n",
    "     'octopus': 67,\n",
    "     'okapi': 68,\n",
    "     'pagoda': 69,\n",
    "     'panda': 70,\n",
    "     'pigeon': 71,\n",
    "     'pizza':72,\n",
    "     'platypus': 73,\n",
    "     'pyramid': 74,\n",
    "     'revolver': 75,\n",
    "     'rhino': 76,\n",
    "     'rooster': 77,\n",
    "     'saxophone': 78,\n",
    "     'schooner': 79,\n",
    "     'scissors': 80,\n",
    "     'scorpion': 81,\n",
    "     'sea_horse': 82,\n",
    "     'snoopy': 83,\n",
    "     'soccer_ball': 84,\n",
    "     'stapler': 85,\n",
    "     'starfish': 86,\n",
    "     'stegosaurus': 87,\n",
    "     'stop_sign': 88,\n",
    "     'strawberry': 89,\n",
    "     'sunflower': 90,\n",
    "     'tick': 91,\n",
    "     'umbrella': 92,\n",
    "     'watch': 93,\n",
    "     'water_lilly': 94,\n",
    "     'wheelchair': 95,\n",
    "     'wild_cat': 96,\n",
    "     'windsor_chair': 97,\n",
    "     'wrench': 98,\n",
    "     'yin_yang': 99,\n",
    "     'crocodile':100,\n",
    "     'trilobite':101, \n",
    "}\n",
    "#class_to_numeric = {class_label: i for i, class_label in enumerate(set(class_labels))}\n",
    "for object_category,images in object_categories_dict_q.items():\n",
    "    for image in images:\n",
    "        dataset_labels_query.append(object_labels_dict_q[object_category])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6133fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize query images \n",
    "X_q, y_q = [], []\n",
    "for object_category,filenames_query_images in object_categories_dict_q.items():\n",
    "    for filename in filenames_query_images:\n",
    "        img = cv2.imread(str(filename))  # Convert Path object to string\n",
    "        resized_img = cv2.resize(img, (224, 224))\n",
    "        X_q.append(resized_img)\n",
    "        y_q.append(object_labels_dict_q[object_category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_q = np.array(X_q) \n",
    "y_q = np.array(y_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccdfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q = X_q / 255.0  # Normalize pixel values to the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_q dimensions:\", x_q.shape)\n",
    "print(\"y_q dimensions:\", y_q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features of query images \n",
    "features_query_model1 = feature_extraction_model1.predict(x_q)\n",
    "features_query_model2 = feature_extraction_model2.predict(x_q)\n",
    "# Concatenate both concatenated feature vectors\n",
    "extracted_features_query_images = Concatenate()([features_query_model1,features_query_model2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb70b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels to the extracted features\n",
    "features_with_labels_q = list(zip(extracted_features_query_images, y_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Iterating over features with their labels\n",
    "for feature, label in features_with_labels_q:\n",
    "    # Access the feature vector and its corresponding label\n",
    "    print(\"Feature shape:\", feature.shape)\n",
    "    print(\"Label:\", label)\n",
    "    # Perform any operations using the feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd7b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the extracted features array\n",
    "features_query_images = tf.reshape(extracted_features_query_images, (len(extracted_features_query_images), -1))\n",
    "print(\"Reshaped features shape:\", features_query_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bcf992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming features is your tensor\n",
    "num_images_q, num_features_per_image_q = features_query_images.shape\n",
    "\n",
    "# Printing the values\n",
    "print(\"Number of images =\", num_images_q)\n",
    "print(\"Number of features per image =\", num_features_per_image_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7696b0",
   "metadata": {},
   "source": [
    "# Perform Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f06b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KDTree\n",
    "import timeit\n",
    "\n",
    "def ret_images_knn(query_features, k):\n",
    "    # Fit a Nearest Neighbors model\n",
    "    nn_model = NearestNeighbors(n_neighbors=k, algorithm='auto')\n",
    "    nn_model.fit(extracted_features)\n",
    "\n",
    "    # Query for the nearest neighbors\n",
    "    start_time = time.time()\n",
    "    distances, top_indices = nn_model.kneighbors(query_features)\n",
    "    end_time = time.time()\n",
    "    retrieval_time = end_time - start_time\n",
    "    print(f\"Retrieval Time: {retrieval_time:.4f} seconds\")\n",
    "    print(\"Distances\", distances) \n",
    "    # Plot the query image\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    plt.subplot(1, 6, 1)\n",
    "    plt.imshow(x_q[query_index])\n",
    "    plt.title(\"Query Image\")\n",
    "\n",
    "    # Plot the top 5 similar images\n",
    "    retrieved_images_with_labels = []\n",
    "    retrieved_labels = []\n",
    "    for i, (index, distance) in enumerate(zip(top_indices[0], distances[0]), start=2):\n",
    "        plt.subplot(1, k+1, i)\n",
    "        plt.imshow(x[index])\n",
    "        plt.title(f\"Similar Image {i-1}\\nDistance: {distance:.4f}\")\n",
    "        # Append the retrieved image and its label to the list\n",
    "        retrieved_images_with_labels.append((x[index], y[index]))\n",
    "        retrieved_labels.append(y[index])\n",
    "    #plt.tight_layout()    \n",
    "    plt.show()\n",
    "    return retrieved_images_with_labels,retrieved_labels,top_indices,retrieval_time\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2defff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(query_labels, retrieved_labels,k):\n",
    "    if len(query_labels) != 1:\n",
    "        raise ValueError(\"The query should have a single label.\")\n",
    "\n",
    "    query_label = query_labels[0]\n",
    "    # Ensure retrieved_labels is a list\n",
    "    if not isinstance(retrieved_labels, list):\n",
    "        retrieved_labels = [retrieved_labels]\n",
    "        \n",
    "    # Ensure k does not exceed the length of retrieved_labels\n",
    "    k = min(k, len(retrieved_labels))    \n",
    "\n",
    "    #for k in k_values:\n",
    "    top_k_retrieved = retrieved_labels[:k]\n",
    "    \n",
    "    # Calculate true positives\n",
    "    true_positive = sum(1 for label in top_k_retrieved if label == query_label)\n",
    "    \n",
    "    # Calculate false positives\n",
    "    false_positive = k - true_positive\n",
    "    \n",
    "    # Calculate false negatives\n",
    "    false_negative = 1 if true_positive == 0 else 0  # There is a false negative if no true positive\n",
    "    \n",
    "    # Calculate true negatives\n",
    "    true_negative = k - true_positive  # Assuming binary classification\n",
    "    \n",
    "    # Calculate accuracy at k\n",
    "    accuracy_at_k = (true_positive + true_negative) / k\n",
    "    \n",
    "    # Calculate precision at k\n",
    "    precision_at_k = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0.0\n",
    "    \n",
    "    # Calculate recall at k\n",
    "    recall_at_k = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0.0\n",
    "    \n",
    "    # Calculate F1 score at k\n",
    "    f_measure_at_k = 2 * (precision_at_k * recall_at_k) / (precision_at_k + recall_at_k) if (precision_at_k + recall_at_k) > 0 else 0.0\n",
    "    \n",
    "    \n",
    "    return precision_at_k, recall_at_k, accuracy_at_k, f_measure_at_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def store_metrics_to_excel(metrics_data, retrieval_methods, filename):\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "    \n",
    "    # Loop over the retrieval methods\n",
    "    for method in retrieval_methods:\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        df = pd.DataFrame(metrics_data[method])\n",
    "        \n",
    "        # Write each DataFrame to a separate sheet\n",
    "        df.to_excel(writer, sheet_name=method, index=False)\n",
    "    \n",
    "    # Close the Pandas Excel writer and save the file\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b623bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving top 20 images\n",
    "k = 5\n",
    "\n",
    "# Initialize an empty dictionary to store metrics data\n",
    "all_metrics_data = {'euclidean': {}}\n",
    "\n",
    "# Loop over all queries\n",
    "for i in range(len(x_q)):\n",
    "    query_labels = []\n",
    "    query_index = i\n",
    "    print(\"Query image\",i)\n",
    "    query_features = tf.reshape(features_query_images[query_index], (1, -1))\n",
    "    print(query_features.shape)\n",
    "    query_label = y_q[query_index]\n",
    "    print(query_label)\n",
    "    query_labels.append(query_label)\n",
    "    \n",
    "    # Perform retrieval using KNN\n",
    "    retrieved_images_with_labels, retrieved_labels, top_indices,retrieval_time = ret_images_knn(query_features, k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['euclidean'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy, retrieval_time]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "# Store all metrics data to an Excel file\n",
    "store_metrics_to_excel(all_metrics_data, ['euclidean'], 'metrics_concat_fusion_mobilnetandeffB0_results_caltech101_retrieving_using_KNN_images.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05507bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving top 20 images\n",
    "k = 30\n",
    "\n",
    "# Initialize an empty dictionary to store metrics data\n",
    "all_metrics_data = {'KNN': {}, 'Cosine Similarity': {}, 'Euclidean Distance': {}}\n",
    "\n",
    "# Loop over all queries\n",
    "for i in range(len(x_q)):\n",
    "    query_labels = []\n",
    "    query_index = i\n",
    "    print(\"Query image\",i)\n",
    "    query_features = tf.reshape(features_query_images[query_index], (1, -1))\n",
    "    print(query_features.shape)\n",
    "    query_label = y_q[query_index]\n",
    "    print(query_label)\n",
    "    query_labels.append(query_label)\n",
    "    \n",
    "    # Retrieve images using cosine similarity\n",
    "    retrieved_images_with_labels, retrieved_labels = ret_images_cosine_similarity(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Cosine Similarity'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Retrieve images using euclidean distance\n",
    "    retrieved_images_with_labels, retrieved_labels, distances = ret_images_euclidean_distance(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Euclidean Distance'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Perform retrieval using KNN\n",
    "    retrieved_images_with_labels, retrieved_labels, top_indices = ret_images_knn(query_features, k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['KNN'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "        \n",
    "# Store all metrics data to an Excel file\n",
    "store_metrics_to_excel(all_metrics_data, ['KNN', 'Cosine Similarity', 'Euclidean Distance'], 'metrics_concat_fusion_mobilnetandeffB0_results_corel1k_retrieving_top30_images.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving top 20 images\n",
    "k = 25\n",
    "\n",
    "# Initialize an empty dictionary to store metrics data\n",
    "all_metrics_data = {'KNN': {}, 'Cosine Similarity': {}, 'Euclidean Distance': {}}\n",
    "\n",
    "# Loop over all queries\n",
    "for i in range(len(x_q)):\n",
    "    query_labels = []\n",
    "    query_index = i\n",
    "    print(\"Query image\",i)\n",
    "    query_features = tf.reshape(features_query_images[query_index], (1, -1))\n",
    "    print(query_features.shape)\n",
    "    query_label = y_q[query_index]\n",
    "    print(query_label)\n",
    "    query_labels.append(query_label)\n",
    "    \n",
    "    # Retrieve images using cosine similarity\n",
    "    retrieved_images_with_labels, retrieved_labels = ret_images_cosine_similarity(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Cosine Similarity'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Retrieve images using euclidean distance\n",
    "    retrieved_images_with_labels, retrieved_labels, distances = ret_images_euclidean_distance(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Euclidean Distance'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Perform retrieval using KNN\n",
    "    retrieved_images_with_labels, retrieved_labels, top_indices = ret_images_knn(query_features, k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['KNN'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "        \n",
    "# Store all metrics data to an Excel file\n",
    "store_metrics_to_excel(all_metrics_data, ['KNN', 'Cosine Similarity', 'Euclidean Distance'], 'metrics_concat_fusion_mobilnetandeffB0_results_corel1k_retrieving_top25_images.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a863ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving top 20 images\n",
    "k = 20\n",
    "\n",
    "# Initialize an empty dictionary to store metrics data\n",
    "all_metrics_data = {'KNN': {}, 'Cosine Similarity': {}, 'Euclidean Distance': {}}\n",
    "\n",
    "# Loop over all queries\n",
    "for i in range(len(x_q)):\n",
    "    query_labels = []\n",
    "    query_index = i\n",
    "    print(\"Query image\",i)\n",
    "    query_features = tf.reshape(features_query_images[query_index], (1, -1))\n",
    "    print(query_features.shape)\n",
    "    query_label = y_q[query_index]\n",
    "    print(query_label)\n",
    "    query_labels.append(query_label)\n",
    "    \n",
    "    # Retrieve images using cosine similarity\n",
    "    retrieved_images_with_labels, retrieved_labels = ret_images_cosine_similarity(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Cosine Similarity'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Retrieve images using euclidean distance\n",
    "    retrieved_images_with_labels, retrieved_labels, distances = ret_images_euclidean_distance(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Euclidean Distance'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Perform retrieval using KNN\n",
    "    retrieved_images_with_labels, retrieved_labels, top_indices = ret_images_knn(query_features, k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['KNN'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "        \n",
    "# Store all metrics data to an Excel file\n",
    "store_metrics_to_excel(all_metrics_data, ['KNN', 'Cosine Similarity', 'Euclidean Distance'], 'metrics_concat_fusion_mobilnetandeffB0_results_corel1k_retrieving_top20_images.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving top 10 images\n",
    "k = 10\n",
    "\n",
    "# Initialize an empty dictionary to store metrics data\n",
    "all_metrics_data = {'KNN': {}, 'Cosine Similarity': {}, 'Euclidean Distance': {}}\n",
    "\n",
    "# Loop over all queries\n",
    "for i in range(len(x_q)):\n",
    "    query_labels = []\n",
    "    query_index = i\n",
    "    print(\"Query image\",i)\n",
    "    query_features = tf.reshape(features_query_images[query_index], (1, -1))\n",
    "    print(query_features.shape)\n",
    "    query_label = y_q[query_index]\n",
    "    print(query_label)\n",
    "    query_labels.append(query_label)\n",
    "    \n",
    "    # Retrieve images using cosine similarity\n",
    "    retrieved_images_with_labels, retrieved_labels = ret_images_cosine_similarity(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Cosine Similarity'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Retrieve images using euclidean distance\n",
    "    retrieved_images_with_labels, retrieved_labels, distances = ret_images_euclidean_distance(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Euclidean Distance'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Perform retrieval using KNN\n",
    "    retrieved_images_with_labels, retrieved_labels, top_indices = ret_images_knn(query_features, k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['KNN'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "        \n",
    "# Store all metrics data to an Excel file\n",
    "store_metrics_to_excel(all_metrics_data, ['KNN', 'Cosine Similarity', 'Euclidean Distance'], 'metrics_concat_fusion_mobilnetandeffB0_results_corel1k_retrieving_top10_images.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "\n",
    "# Initialize an empty dictionary to store metrics data\n",
    "all_metrics_data = {'KNN': {}, 'Cosine Similarity': {}, 'Euclidean Distance': {}}\n",
    "\n",
    "# Loop over all queries\n",
    "for i in range(len(x_q)):\n",
    "    query_labels = []\n",
    "    query_index = i\n",
    "    print(\"Query image\",i)\n",
    "    query_features = tf.reshape(extracted_features_query_images[query_index], (1, -1))\n",
    "    query_label = y_q[query_index]\n",
    "    print(query_label)\n",
    "    query_labels.append(query_label)\n",
    "    \n",
    "    # Retrieve images using cosine similarity\n",
    "    retrieved_images_with_labels, retrieved_labels = ret_images_cosine_similarity(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Cosine Similarity'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Retrieve images using euclidean distance\n",
    "    retrieved_images_with_labels, retrieved_labels, distances = ret_images_euclidean_distance(query_features,k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['Euclidean Distance'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Perform retrieval using KNN\n",
    "    retrieved_images_with_labels, retrieved_labels, top_indices = ret_images_knn(query_features, k)\n",
    "    precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels, k)\n",
    "    all_metrics_data['KNN'][f\"Query {i + 1}\"] = [precision, recall, f1, accuracy]\n",
    "    print(\"Query labels\", query_labels,\"\\n\")\n",
    "    print(\"Retrieved Labels\", retrieved_labels,\"\\n\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "        \n",
    "# Store all metrics data to an Excel file\n",
    "store_metrics_to_excel(all_metrics_data, ['KNN', 'Cosine Similarity', 'Euclidean Distance'], 'metrics_concat_fusion_mobilnetandeffB0_results_caltech101.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0590cc6f",
   "metadata": {},
   "source": [
    "# End of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143461d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#Retrieve images using cosine similarity\n",
    "def ret_images_cosine_similarity(query_features):\n",
    "    similarity_scores = cosine_similarity(query_features, embedded_features)\n",
    "    #print(similarity_scores)\n",
    "    # Get the indices of the top 5 most similar images (excluding the query image itself)\n",
    "    top_indices = np.argsort(similarity_scores[0])[::-1][1:6]\n",
    "    #print(top_indices)\n",
    "    # Plot the query image\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.subplot(1, 6, 1)\n",
    "    plt.imshow(x[query_index])\n",
    "    plt.title(\"Query Image\")\n",
    "\n",
    "    # Plot the top 5 similar images\n",
    "    retrieved_images_with_labels = []\n",
    "    retrieved_labels = []\n",
    "    for i, index in enumerate(top_indices, start=2):\n",
    "        print(\"Index:\", index)\n",
    "        plt.subplot(1, 6, i)\n",
    "        plt.imshow(x[index])\n",
    "        plt.title(f\"Similar Image {i-1}\")\n",
    "        # Append the retrieved image and its label to the list\n",
    "        retrieved_images_with_labels.append((x[index], y[index]))\n",
    "    \n",
    "        retrieved_labels.append(y[index])\n",
    "    plt.tight_layout()    \n",
    "    plt.show()\n",
    "    return retrieved_images_with_labels,retrieved_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve images using cosine similarity\n",
    "retrieved_images_with_labels,retrieved_labels = ret_images_cosine_similarity(query_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16207a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(retrieved_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713fc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def ret_images_euclidean_distance(query_features):\n",
    "    # Calculate Euclidean distances\n",
    "    distances = euclidean_distances(query_features, embedded_features)\n",
    "    # Get the indices of the top 5 most similar images\n",
    "    top_indices = np.argsort(distances[0])[:5]\n",
    "    #print(top_distances)\n",
    "    # Plot the query image\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.subplot(1, 6, 1)\n",
    "    plt.imshow(x[query_index])\n",
    "    plt.title(\"Query Image\")\n",
    "\n",
    "    # Plot the top 5 similar images\n",
    "    retrieved_images_with_labels = []\n",
    "    retrieved_labels = []\n",
    "    for i, index in enumerate(top_indices, start=2):\n",
    "        plt.subplot(1, 6, i)\n",
    "        plt.imshow(x[index])\n",
    "        plt.title(f\"Similar Image {i-1}\")\n",
    "        # Append the retrieved image and its label to the list\n",
    "        retrieved_images_with_labels.append((x[index], y[index]))\n",
    "        retrieved_labels.append(y[index])\n",
    "    plt.tight_layout()    \n",
    "    plt.show()\n",
    "    return retrieved_images_with_labels,retrieved_labels,distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ba3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieved_images_with_labels,retrieved_labels,distances = ret_images_euclidean_distance(query_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00343281",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "def ret_images_knn(query_features, k=5):\n",
    "    # Fit a Nearest Neighbors model\n",
    "    nn_model = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "    nn_model.fit(embedded_features)\n",
    "\n",
    "    # Query for the nearest neighbors\n",
    "    distances, top_indices = nn_model.kneighbors(query_features)\n",
    "    print(distances) \n",
    "    # Plot the query image\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    plt.subplot(1, 6, 1)\n",
    "    plt.imshow(x[query_index])\n",
    "    plt.title(\"Query Image\")\n",
    "\n",
    "    # Plot the top 5 similar images\n",
    "    retrieved_images_with_labels = []\n",
    "    retrieved_labels = []\n",
    "    for i, (index, distance) in enumerate(zip(top_indices[0], distances[0]), start=2):\n",
    "        plt.subplot(1, 6, i)\n",
    "        plt.imshow(x[index])\n",
    "        plt.title(f\"Similar Image {i-1}\\nDistance: {distance:.4f}\")\n",
    "        # Append the retrieved image and its label to the list\n",
    "        retrieved_images_with_labels.append((x[index], y[index]))\n",
    "        retrieved_labels.append(y[index])\n",
    "    #plt.tight_layout()    \n",
    "    plt.show()\n",
    "    return retrieved_images_with_labels,retrieved_labels,top_indices\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform retrieval using KNN\n",
    "retrieved_images_with_labels,retrieved_labels,top_indices = ret_images_knn(query_features, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f172221",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(query_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ed005",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(retrieved_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cebd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(query_labels, retrieved_labels,k):\n",
    "    if len(query_labels) != 1:\n",
    "        raise ValueError(\"The query should have a single label.\")\n",
    "\n",
    "    query_label = query_labels[0]\n",
    "    # Ensure retrieved_labels is a list\n",
    "    if not isinstance(retrieved_labels, list):\n",
    "        retrieved_labels = [retrieved_labels]\n",
    "        \n",
    "    # Ensure k does not exceed the length of retrieved_labels\n",
    "    k = min(k, len(retrieved_labels))    \n",
    "\n",
    "    #for k in k_values:\n",
    "    top_k_retrieved = retrieved_labels[:k]\n",
    "    \n",
    "    # Calculate true positives\n",
    "    true_positive = sum(1 for label in top_k_retrieved if label == query_label)\n",
    "    \n",
    "    # Calculate false positives\n",
    "    false_positive = k - true_positive\n",
    "    \n",
    "    # Calculate false negatives\n",
    "    false_negative = 1 if true_positive == 0 else 0  # There is a false negative if no true positive\n",
    "    \n",
    "    # Calculate true negatives\n",
    "    true_negative = k - true_positive  # Assuming binary classification\n",
    "    \n",
    "    # Calculate accuracy at k\n",
    "    accuracy_at_k = (true_positive + true_negative) / k\n",
    "    \n",
    "    # Calculate precision at k\n",
    "    precision_at_k = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0.0\n",
    "    \n",
    "    # Calculate recall at k\n",
    "    recall_at_k = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0.0\n",
    "    \n",
    "    # Calculate F1 score at k\n",
    "    f_measure_at_k = 2 * (precision_at_k * recall_at_k) / (precision_at_k + recall_at_k) if (precision_at_k + recall_at_k) > 0 else 0.0\n",
    "    \n",
    "    \n",
    "    return precision_at_k, recall_at_k, accuracy_at_k, f_measure_at_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc014c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "# Example usage\n",
    "precision, recall, accuracy, f1 = calculate_metrics(query_labels, retrieved_labels,k)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_relevance_scores(distances, epsilon=1e-6):\n",
    "    # Convert distances to relevance scores\n",
    "    relevance_scores = 1 / (np.array(distances) + epsilon)\n",
    "    return relevance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distances)\n",
    "relevance_scores = calculate_relevance_scores(distances)\n",
    "relevance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab861f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg(relevance_scores, k=None):\n",
    "    # Sort relevance scores in descending order\n",
    "    sorted_scores = np.sort(relevance_scores)[::-1]\n",
    "    if k is None:\n",
    "        k = len(relevance_scores)\n",
    "\n",
    "    # Calculate DCG (Discounted Cumulative Gain)\n",
    "    dcg = np.sum((2 ** sorted_scores - 1) / np.log2(np.arange(2, len(sorted_scores) + 2)))\n",
    "\n",
    "    # Calculate IDCG (Ideal Discounted Cumulative Gain)\n",
    "    num_rel = min(len(relevance_scores), k)\n",
    "    ideal_scores = np.sort(1 / np.arange(1, num_rel + 1))[::-1]\n",
    "    idcg = np.sum((2 ** ideal_scores - 1) / np.log2(np.arange(2, len(ideal_scores) + 2)))\n",
    "    \n",
    "    # Check if IDCG is zero to avoid division by zero\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate NDCG (Normalized Discounted Cumulative Gain)\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53811c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg = calculate_ndcg(relevance_scores)\n",
    "print(\"NDCG:\", ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52225ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
